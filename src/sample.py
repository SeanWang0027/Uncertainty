"""Sample the sequences generated by the model."""
import os
import argparse
import pickle
from models import LanguageModel
from collections import defaultdict
from tqdm import tqdm


_VALID_LM_NAMES = {
    'gpt2': 'gpt2',
    'mistralai/Mistral-7B-v0.1': 'mistral',
    'tiiuae/falcon-7b': 'falcon',
    'mosaicml/mpt-7b': 'mpt',
    '01-ai/Yi-6B': 'yi',
    'meta-llama/Meta-Llama-3-8B': 'llama3',
    'meta-llama/Llama-2-7b-hf': 'llama2'
}


class Sampler(object):
    """Sampler to sample answer from the model."""
    def __init__(self, model_name: str, dataset: str) -> None:
        """Initialize the sampler model and the dataset used for sampling response.

        Args:
            model_name (str): The name of the model.
            dataset (str): The name of the dataset.
        """
        self.model = LanguageModel(model_name)
        self.dataset = dataset
        self.load_data()

    def load_data(self) -> None:
        """Load the data based on the name of the dataset."""
        if self.dataset == 'trivia_qa':
            self.data_file = '../../../data/trivia_qa_train.pkl'
            self.prompt_data_file = '../../../data/trivia_qa_test.pkl'
            self.data = pickle.load(open(self.data_file, "rb"))
            self.prompt_data = pickle.load(open(self.prompt_data_file, "rb"))
        if self.dataset == 'webquestions':
            self.data_file = '../../../data/webquestions_train.pkl'
            self.prompt_data_file = '../../../data/webquestions_test.pkl'
            self.data = pickle.load(open(self.data_file, "rb"))
            self.prompt_data = pickle.load(open(self.prompt_data_file, "rb"))
        if self.dataset == 'SQuAD':
            self.data_file = '../../../data/SQuAD_validation.pkl'
            self.prompt_data_file = '../../../data/SQuAD_train.pkl'
            self.data = pickle.load(open(self.data_file, "rb"))
            self.prompt_data = pickle.load(open(self.prompt_data_file, "rb"))
        if self.dataset == 'WikiQA':
            self.data_file = '../../../data/WikiQA_train.pkl'
            self.prompt_data_file = '../../../data/WikiQA_test.pkl'
            self.data = pickle.load(open(self.data_file, "rb"))
            self.prompt_data = pickle.load(open(self.prompt_data_file, "rb"))

    def format_prompt(self, example: dict, index: int, k_shot=0) -> dict:
        """Format the prompt for sampling.

        Args:
            example (dict): The data point object.
            index (int): The index for id.
            k_shot (int): The k shot for the trivia qa prompting.

        Returns:
            A dict which contain necessary example for sampling.
        """
        exp = dict()
        exp["id"] = index
        exp['answer'] = example['answers'] if self.dataset == 'webquestions' else example['answer']
        prompt = ""
        if self.dataset == 'trivia_qa':
            PROMPT = "Answer these questions.\n"
            for i in range(k_shot):
                PROMPT += 'Q: ' + self.prompt_data[i]['question'] + '\nA: ' + self.prompt_data[i]['answer'] + '\n'
            prompt += PROMPT + 'Q: ' + example['question'] + '\nA: '
        if self.dataset == 'webquestions':
            PROMPT = "Answer these questions.\n"
            for i in range(k_shot):
                answer = self.prompt_data[i]['answers'][0]
                PROMPT += 'Q: ' + self.prompt_data[i]['question'] + '\nA: ' + answer + '\n'
            prompt += PROMPT + 'Q: ' + example['question'] + '\nA: '
        if self.dataset == 'SQuAD':
            title = []
            PROMPT = "Answer these questions.\n"
            i = 0
            while len(title) <= k_shot:
                if self.prompt_data[i]['title'] in title:
                    i += 1
                    continue
                title.append(self.prompt_data[i]['title'])
                context = self.prompt_data[i]['context']
                answer = self.prompt_data[i]['answer']
                PROMPT += 'Context: ' + context + '\nQuestion: ' + self.prompt_data[i]['question'] + '\nAnswer: ' + answer + '\n'
                i += 1
            prompt += PROMPT + 'Context: ' + example['context'] + '\nQuestion: ' + example['question'] + '\nAnswer: '
        if self.dataset == 'WikiQA':
            question = []
            PROMPT = "Answer these questions.\n"
            i = 0
            while len(question) <= k_shot:
                if self.prompt_data[i]['question'] in question:
                    i += 1
                    continue
                question.append(self.prompt_data[i]['question'])
                context = self.prompt_data[i]['context']
                answer = self.prompt_data[i]['answer']
                PROMPT += 'Context: ' + context + '\nQuestion: ' + self.prompt_data[i]['question'] + '\nAnswer: ' + answer + '\n'
                i += 1
            prompt += PROMPT + 'Context: ' + example['context'] + '\nQuestion: ' + example['question'] + '\nAnswer: '
        exp["prompt"] = prompt
        return exp

    def sample(self, start: int, end: int, num_responses: int, stored_path='../../../output/', k_shot=0) -> None:
        """Sample the result for questions in the datasets, from the start index to end index, and stored in .pkl file.

        Args:
            start (int): The start index of the sampling.
            end (int): The end index of the sampling.
            num_responses (int): Time for sampling for a single point.
            stored_path (str): The path for .pkl saved path.
            k_shot (int): The k shot for the trivia qa prompting.
        """
        if self.model._model_name in _VALID_LM_NAMES:
            model_name = _VALID_LM_NAMES[self.model._model_name] + '/'
        if not os.path.exists(f'{stored_path}{model_name}{self.dataset}/'):
            os.makedirs(f'{stored_path}{model_name}{self.dataset}/', exist_ok=True)
        stored_path = f'{stored_path}{model_name}{self.dataset}/{self.dataset}_{start}_{end}_{num_responses}.pkl'
        if os.path.exists(stored_path):
            with open(stored_path, 'rb') as f:
                while True:
                    try:
                        data = pickle.load(f)
                        start = data['id']
                    except EOFError:
                        break
            start += 1
        end = min(end, len(self.data))
        for i in tqdm(range(start, end)):
            exp = self.format_prompt(self.data[i], index=i, k_shot=k_shot)
            answer = exp['answer'][0] if self.dataset == 'webquestions' else exp['answer']
            answers = exp['answer'] if self.dataset == 'webquestions' else [exp['answer']]
            max_tokens = 4 if len(self.model._tokenizer(' ' + answer, add_special_tokens=False)) < 4 else len(self.model._tokenizer(' ' + exp['answer'], add_special_tokens=False))
            exp['responses'] = self.model.generate_response(exp['prompt'], answer, num_responses, max_new_tokens=max_tokens)
            exp['exist_answer'] = False
            exp['candidates_logit'] = dict()
            if self.dataset == 'webquestions':
                responses = defaultdict(int)
                for key, val in exp['responses'].items():
                    for ans in answers:
                        if ans in key:
                            exp['exist_answer'] = True
                            responses[answer] += val
                            if answer not in exp['candidates_logit']:
                                exp['candidates_logit'][answer] = 1
                        else:
                            responses[key] += val
                            exp['candidates_logit'][key] = 1
                exp['responses'] = responses
            if self.dataset == 'trivia_qa' or self.dataset == 'SQuAD' or self.dataset == 'WikiQA':
                for key in exp['responses'].keys():  # PARTIAL MATCH RULES
                    if key == '':
                        continue
                    key = key.split('\n')[0]
                    if answer in key:
                        exp['exist_answer'] = True
                        if answer not in exp['candidates_logit']:
                            exp['candidates_logit'][answer] = 1
                    else:
                        exp['candidates_logit'][key] = 1
            if answer not in exp['candidates_logit']:
                exp['candidates_logit'][answer] = 1
            if not exp['exist_answer']:
                exp['responses'][answer] = 0
            exp = self.model.resample(exp)
            with open(stored_path, 'ab') as f:
                pickle.dump(exp, f)


def main() -> None:
    """The main function for sampling."""
    parser = argparse.ArgumentParser(description='Prefix Finetuning for GPT2 models.')
    parser.add_argument('--model_name', type=str, required=True, help='Initial model name to do the prefix finetuning.')
    parser.add_argument('--dataset', type=str, default='mmlu', help='The output json path for the result.')
    parser.add_argument('--start', type=int, required=True, help='The start index of the sampling.')
    parser.add_argument('--end', type=int, required=True, help='The end index of the sampling.')
    parser.add_argument('--num_responses', type=int, required=True, help='The sampling times.')
    parser.add_argument('--k_shot', type=int, default=0, help='The value for k shot.')
    args = parser.parse_args()
    model_name = args.model_name
    dataset = args.dataset
    sampler = Sampler(model_name=model_name, dataset=dataset)
    sampler.sample(start=args.start, end=args.end, num_responses=args.num_responses, k_shot=args.k_shot)


if __name__ == '__main__':
    main()